<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>PyDBase: pydbase</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">PyDBase
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">pydbase </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="autotoc_md1"></a>
High speed database with key / data</h1>
<p>The motivation was to create a no frills way of saving / retrieving data. It is fast, and the time test shows that this is an order of magnitude faster than most mainstream databases. This is due to the engine's simplicity. It avoids expensive computations in favor of quickly saving data.</p>
<h2><a class="anchor" id="autotoc_md2"></a>
Fast data save / retrieve</h2>
<p>Mostly ready for production. All tests pass. Please use caution, as this is new. The command line tester can drive most aspects of this API; and it is somewhat complete. It is also good way to see the API / Module in action.</p>
<h1><a class="anchor" id="autotoc_md3"></a>
API</h1>
<p>The module 'twincore' uses two data files and a lock file. The file names are generated from the base name of the data file; name.pydb for data; name.pidx for the index, name.lock for the lock file. In case of frozen process the lock file times out in xx seconds and breaks the lock. If the locking process (id in lockfile) does not exist, the lock breaks immediately.</p>
<p>Setting verbosity and debug level: </p><pre class="fragment">twincore.core_quiet   = quiet
twincore.core_verbose = verbose
twincore.core_pgdebug = pgdebug
twincore.core_showdel = sdelx
</pre><p> (Setting before data creation will display mesages from the construtor)</p>
<p>Example db creation: </p><pre class="fragment">core = twincore.TwinCore(datafile_name)
</pre><p> Some basic ops: </p><pre class="fragment">dbsize = core.getdbsize()

core.save_data(keyx, datax)
rec_arr = core.retrieve(keyx, ncount)
print("rec_arr", rec_arr)
</pre> <h2><a class="anchor" id="autotoc_md4"></a>
Structure of the data:</h2>
<pre class="fragment">32 byte header, starting with FILESIG

4 bytes    4 bytes          4 bytes         Variable
------------------------------------------------------------
RECSIG     Hash_of_key      Len_of_key      DATA_for_key
RECSEP     Hash_of_payload  Len_of_payload  DATA_for_payload

    .
    .

RECSIG     Hash_of_key      Len_of_key      DATA_for_key
RECSEP     Hash_of_payload  Len_of_payload  DATA_for_payload

where:
RECSIG="RECB" (record begin here)
RECSEP="RECS" (record separated here)
RECDEL="RECX" (record deleted)

Deleted records are marked with the RECSIG mutated from RECB to RECX

  Vacuum will remove the deleted records; Make sure your database has no
pending ops; or non atomic opts;

    (like: find keys - delete keys in two ops)

  New data is appended to the end, no duplicate filtering is done.
Retrieval is searched from reverse, the latest record with this key
is retrieved first. Most of the times this behavior is what we
want; also the record history is kept this way, also a desirable
behavior.
</pre> <h1><a class="anchor" id="autotoc_md5"></a>
The db exerciser executable script 'pydbase.py':</h1>
<p>The file <a class="el" href="pydbase_8py.html">pydbase.py</a> exercises most of the twincore functionality. It also provides examples of how to drive it.</p>
<p>The command line utility's help response:</p>
<p>Usage: pydebase.py [options] [arg_key arg_data] Options: -h help (this screen) -|- -i show deleted on dump -V print version -|- -q quiet on -d debug level (0-10) -|- -v increment verbosity level -r randomize data -|- -w write fixed record(s) -z dump backwards(s) -|- -i show deleted record(s) -U Vacuum DB -|- -R reindex / recover DB -I DB Integrity check -|- -c set check integrity flag -s Skip to count recs -|- -K list keys only -y key find by key -|- -m dump data to console -o offs get data from offset -|- -e offs delete at offset -u rec delete at position -|- -g num get number of recs. -k key key to save -|- -a str data to save -S print num recs -|- -D key delete by key -n num number of records -|- -t key retrieve by key -p num skip number of records on get -l lim limit number of records on get -x max limit max number of records to get -f file input or output file (default: 'data/pydbase.pydb') The default action is to dump records to screen in reverse order. On the command line, use quotes for multi word arguments.</p>
<h2><a class="anchor" id="autotoc_md6"></a>
Comparison to other databases:</h2>
<p>This comparison is to show the time it takes to write 500 records. In the tests the record size is about the same (Hello, 1 /vs/ "Hello", 1) Please see the sqlite_test.sql for details of data output;</p>
<p>The test can be repeated with running the 'time.sh' script file. Please note the the time.sh clears all files test_data/* for a fair test. </p><pre class="fragment">    sqlite time test, writing 500 records ...
    real    0m1.730s
    user    0m0.110s
    sys 0m0.455s

    pydbase time test, writing 500 records ...
    real    0m0.120s
    user    0m0.075s
    sys 0m0.044s

    -rw-r--r-- 1 peterglen users  4032 Feb  7 15:35 pydb_test.pidx
    -rw-r--r-- 1 peterglen users 15032 Feb  7 15:35 pydb_test.pydb
    -rw-r--r-- 1 peterglen users 20480 Feb  7 15:35 sqlite_test.db
</pre><p> Please mind the fact that the sqlite engine has to do a lot of parsing which we skip doing; That is why pydbase is more than an order of magnitude faster ...</p>
<h2><a class="anchor" id="autotoc_md7"></a>
Saving more complex data</h2>
<p>The database saves a key / value pair. However, the key can be mutated to contain meta data. (for example adding a string in front of it.) [like: CUST_ for customer data / details] Also the key can be made unique by adding a UUID to it.</p>
<p>The data can consist of any text / binary. The library <a class="el" href="pypacker_8py.html">pypacker.py</a> can pack any data into a string; A copy of pypacker is included here.</p>
<h1><a class="anchor" id="autotoc_md8"></a>
pypacker.py</h1>
<p>This module can pack arbitrary python data into a string; which can be used to store anything in the pydbase key / data sections.</p>
<p>Example from running <a class="el" href="testpacker_8py.html">testpacker.py</a>: </p><pre class="fragment">    org: (1, 2, 'aa', ['bb', b'dd'])
    packed: pg s4 'iisa' i4 1 i4 2 s2 'aa' a29 'pg s2 'sb' s2 'bb' b4 'ZGQ=' '
    unpacked: [1, 2, 'aa', ['bb', b'dd']]
    rec_arr: pg s4 'iisa' i4 1 i4 2 s2 'aa' a29 'pg s2 'sb' s2 'bb' b4 'ZGQ=' '
    rec_arr_upacked: [1, 2, 'aa', ['bb', b'dd']]
    (Note: the decode returns an array of data; use data[0] to get the original)
</pre><p> There is also the option of using pypacker on the key itself. Because the key is identified by its hash, there is no speed penalty; Note that the hash is a 32 bit one; collisions are possible, however unlikely; To compensate, make sure you compare the key proper with the returned key.</p>
<h1><a class="anchor" id="autotoc_md9"></a>
PyTest</h1>
<p>The pytest passes with no errors; Run it from the tests/ directory.</p>
<p>The following (and more) test are created / executed:</p>
<p>collected 24 items</p>
<p>test_bindata.py . [ 4%] test_create.py ..... [ 25%] test_del.py . [ 29%] test_dump.py . [ 33%] test_find.py .. [ 41%] test_findrec.py .. [ 50%] test_getrec.py . [ 54%] test_integrity.py . [ 58%] test_multi.py . [ 62%] test_packer.py ...... [ 87%] test_randdata.py . [ 91%] test_reindex.py . [ 95%] test_vacuum.py . [100%]</p>
<h1><a class="anchor" id="autotoc_md10"></a>
Maintenance</h1>
<p>The DB can rebuild its index and purge all deleted records. In the test utility the options are: </p><pre class="fragment">    ./pydbase.py -U     for vacuum (add -v for verbosity)
</pre><p> The database is re-built, the deleted entries are purged, the damaged data (if any) is saved into a separate file, created with the same base name as the data base, with the '.perr' extension. </p><pre class="fragment">  ./pydbase.py -R     for re-index
</pre><p> The index is recreated; as of the current file contents. This is useful if the index is lost (like copying the data only)</p>
<p>If there is a data file without the index, the re-indexing is called automatically. In case of deleted data file, pydbase will recognize the dangling index and nuke it by renaming it to orgfilename.pidx.dangle (Tue 07.Feb.2023 just deleted it);</p>
<p>Note about the 'garbage' and 'old_tries' directory ... older stuff I tried; some are really useful; For instance take a look at the simplifier: an array of indexes to save offsets and lengths; The simplifier makes one range out of overlapping or close to each other ranges. (min. dist=4)</p>
<p>The database grows with every record added to it. It does not check if the particular record already exists. It adds the new record version to the end; Retrieving starts from the end, and the data retrieved (for this particular key) is the last record saved. All the other records of this key are also there in chronological (save) order. Miracle of record history archived by default.</p>
<p>To clean the old record history, one may delete all the records with this same key, except the last one.</p>
<h2><a class="anchor" id="autotoc_md11"></a>
TODO</h2>
<pre class="fragment">Speed this up by implementing this as a 'C' module
</pre><p> ; EOF </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7
</small></address>
</body>
</html>
